{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.special import expit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return expit(x)\n",
    "def tanh(x):\n",
    "    return  (np.exp(x) - np.exp(-x)) / (np.exp(x) - np.exp(-x))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "自用CNN代码，目前正在实现自定义数量的隐藏层和神经元数量的功能"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 如果采用sigmoid函数（g(z)）的导数是g(z) * (1 - g(z))\n",
    "def d_sigmoid(x):\n",
    "    return x * (1 - x)\n",
    "def d_tanh(x):\n",
    "    return 1 - np.power(x, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class Choose_"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class CNN(object):\n",
    "    def __init__(self, learning_rate, input_cells, output_cells,train_dataset, target,  test_dataset, test_target):\n",
    "        self.layers_output = []\n",
    "        self.learning_rate = learning_rate\n",
    "        self.input_cells = input_cells\n",
    "        self.output_cells = output_cells\n",
    "        # 训练集，不包含目标值\n",
    "        self.train_dataset = train_dataset\n",
    "        # 训练集目标值\n",
    "        self.target = target\n",
    "        # 测试集\n",
    "        self.test_dataset = test_dataset\n",
    "        # 测试集目标值\n",
    "        self.test_target = test_target\n",
    "        self.theta = []\n",
    "\n",
    "    # 创建神经网络，初始化权重矩阵\n",
    "    def create_net(self, hidden_layers):\n",
    "        self.layers = hidden_layers + 2\n",
    "        # hidden_layers 表示隐藏层的数量， 而hidden_cells_(number)存储了对应每个隐藏层的数量，而theta表示从第上一层到下一层的权重，初值使用正态分布生成\n",
    "        # 以下代码可优化 (尴尬，原本是用exec生成一堆变量的，感觉和用列表没啥区别……感觉用列表的话这部分代码还可以用向量乘来简化)\n",
    "        self.cells = [self.input_cells]\n",
    "        for i in range(hidden_layers):\n",
    "            # i表示第几个xx层\n",
    "            self.cells.append(int(input(\"input\" + str(hidden_layers) + \"numbers\")))\n",
    "        self.cells.append(self.output_cells)\n",
    "        for i in range(1, self.layers):\n",
    "            self.theta.append(np.random.normal(size=(self.cells[i], self.cells[i - 1])))\n",
    "            # self.theta.append(np.ones(shape=(self.cells[i], self.cells[i - 1])) * 0.5)\n",
    "            # 0, np.power(self.cells[i], -0.5),\n",
    "            # 以上代码可优化\n",
    "\n",
    "    # 正向传播过程\n",
    "    def output_session(self, input_values):\n",
    "        #每层的输入都是是x * 1的，然后每层到下一层的变量的size是(下层的神经元数量) * (这层的神经元数量)\n",
    "        self.layers_output = [np.array(input_values, ndmin=2).T]\n",
    "        # 第二层开始到最后一层（也就是第一个隐藏层的输入值，存在一个问题，万一没有输入隐藏层？\n",
    "        for i in range(0, self.layers - 1):\n",
    "            layers_input = np.dot(self.theta[i], self.layers_output[i])\n",
    "            self.layers_output.append(expit(layers_input))\n",
    "    # 反向传播算法\n",
    "    # 梯度下降\n",
    "    def back_propagation(self, target_values):\n",
    "        err = [target_values - self.layers_output[self.layers - 1]]\n",
    "        # print(err)\n",
    "        for i in range(1, self.layers - 1):\n",
    "            # print(err[i])\n",
    "            err.append(np.dot(self.theta[-i].T, err[i - 1]))\n",
    "        for i in range(self.layers - 1):\n",
    "            self.theta[self.layers - i - 2] += self.learning_rate * np.dot(err[i] * d_sigmoid(self.layers_output[self.layers - i - 1]), self.layers_output[self.layers - i - 2].T)\n",
    "            # print(self.theta[-i - 1])\n",
    "\n",
    "\n",
    "    def normalization(self, case=1):\n",
    "        # 标准归一化\n",
    "        if case == 0:\n",
    "            self.train_dataset = (self.train_dataset - self.train_dataset.min()) / (self.train_dataset.max() - self.train_dataset.min())\n",
    "            self.test_dataset = (self.test_dataset - self.test_dataset.min()) / (self.test_dataset.max() - self.test_dataset.min())\n",
    "        # 神经网络归一化，要求全大于等于1\n",
    "        elif case == 1:\n",
    "            self.train_dataset = np.log10(self.train_dataset + 1) / np.log10(self.train_dataset.max() + 1)\n",
    "            self.test_dataset = np.log10(self.test_dataset + 1) / np.log10(self.test_dataset.max() + 1)\n",
    "        elif case == 2:\n",
    "            self.train_dataset = self.train_dataset / 255 * 0.99 + 0.01\n",
    "            self.test_dataset = self.test_dataset / 255 * 0.99 + 0.01\n",
    "        else:\n",
    "            print(\" \")\n",
    "    # 训练神经网络\n",
    "    def train(self):\n",
    "        lines = self.train_dataset.shape[0]\n",
    "        for i in range(lines):\n",
    "            self.output_session(self.train_dataset[i])\n",
    "            self.back_propagation(self.target[i])\n",
    "    # 使用测试集进行测试\n",
    "    def test(self):\n",
    "        lines = self.test_dataset.shape[0]\n",
    "        results = []\n",
    "        cnt = 0\n",
    "        for i in range(lines):\n",
    "            self.output_session(self.test_dataset[i])\n",
    "            results.append(np.argmax(self.layers_output[-1]))\n",
    "            if results[i] == np.argmax(self.test_target[i]):\n",
    "                cnt += 1\n",
    "        accuracy = cnt / lines * 100\n",
    "        return results, accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}